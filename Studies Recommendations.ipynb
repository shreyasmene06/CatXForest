{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187758b1",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "832287d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Casey</td>\n",
       "      <td>paul.casey.1@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Sandoval</td>\n",
       "      <td>danielle.sandoval.2@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>tina.andrews.3@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Clark</td>\n",
       "      <td>tara.clark.4@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Campos</td>\n",
       "      <td>anthony.campos.5@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name last_name                                  email  gender  \\\n",
       "0   1       Paul     Casey         paul.casey.1@gslingacademy.com    male   \n",
       "1   2   Danielle  Sandoval  danielle.sandoval.2@gslingacademy.com  female   \n",
       "2   3       Tina   Andrews       tina.andrews.3@gslingacademy.com  female   \n",
       "3   4       Tara     Clark         tara.clark.4@gslingacademy.com  female   \n",
       "4   5    Anthony    Campos     anthony.campos.5@gslingacademy.com    male   \n",
       "\n",
       "   part_time_job  absence_days  extracurricular_activities  \\\n",
       "0          False             3                       False   \n",
       "1          False             2                       False   \n",
       "2          False             9                        True   \n",
       "3          False             5                       False   \n",
       "4          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  \n",
       "0               87  \n",
       "1               90  \n",
       "2               94  \n",
       "3               86  \n",
       "4               76  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"student-scores.csv\")\n",
    "df = df1.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f3efa",
   "metadata": {},
   "source": [
    "# drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e5e304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.drop(columns=['id','first_name','last_name','email'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad3f4c",
   "metadata": {},
   "source": [
    "# create new features from all score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39b35efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0    male          False             3                       False   \n",
       "1  female          False             2                       False   \n",
       "2  female          False             9                        True   \n",
       "3  female          False             5                       False   \n",
       "4    male          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"total_score\"] = df[\"math_score\"] + df[\"history_score\"] + df[\"physics_score\"] + df[\"chemistry_score\"] + df[\"biology_score\"] + df[\"english_score\"] + df[\"geography_score\"]\n",
    "df[\"average_score\"] = df[\"total_score\"] / 7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d54218d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0    male          False             3                       False   \n",
       "1  female          False             2                       False   \n",
       "2  female          False             9                        True   \n",
       "3  female          False             5                       False   \n",
       "4    male          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd850b",
   "metadata": {},
   "source": [
    "# Encoding Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52d54762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Create a LabelEncoder object\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# # Encode categorical columns using label encoder\n",
    "# df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "# df['part_time_job'] = label_encoder.fit_transform(df['part_time_job'])\n",
    "# df['extracurricular_activities'] = label_encoder.fit_transform(df['extracurricular_activities'])\n",
    "# df['career_aspiration'] = label_encoder.fit_transform(df['career_aspiration'])\n",
    "# Define mapping dictionaries for categorical features\n",
    "gender_map = {'male': 0, 'female': 1}\n",
    "part_time_job_map = {False: 0, True: 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}\n",
    "career_aspiration_map = {\n",
    "        'Lawyer': 0, 'Doctor': 1, 'Government Officer': 2, 'Artist': 3, 'Unknown': 4,\n",
    "        'Software Engineer': 5, 'Teacher': 6, 'Business Owner': 7, 'Scientist': 8,\n",
    "        'Banker': 9, 'Writer': 10, 'Accountant': 11, 'Designer': 12,\n",
    "        'Construction Engineer': 13, 'Game Developer': 14, 'Stock Investor': 15,\n",
    "        'Real Estate Developer': 16\n",
    "    }\n",
    "# Apply mapping to the DataFrame\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['part_time_job'] = df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fc961a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0       0              0             3                           0   \n",
       "1       1              0             2                           0   \n",
       "2       1              0             9                           1   \n",
       "3       1              0             5                           0   \n",
       "4       0              0             5                           0   \n",
       "\n",
       "   weekly_self_study_hours  career_aspiration  math_score  history_score  \\\n",
       "0                       27                  0          73             81   \n",
       "1                       47                  1          90             86   \n",
       "2                       13                  2          81             97   \n",
       "3                        3                  3          71             74   \n",
       "4                       10                  4          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8c23b",
   "metadata": {},
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7fd61cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "473b122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_aspiration\n",
       "5     315\n",
       "7     309\n",
       "4     223\n",
       "9     169\n",
       "0     138\n",
       "11    126\n",
       "1     119\n",
       "16     83\n",
       "15     73\n",
       "13     68\n",
       "3      67\n",
       "14     63\n",
       "2      61\n",
       "6      59\n",
       "12     56\n",
       "8      39\n",
       "10     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6e9f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']\n",
    "\n",
    "# Apply SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14149af8",
   "metadata": {},
   "source": [
    "# Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2dd8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12984069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a93ee",
   "metadata": {},
   "source": [
    "# Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e08701dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37bcd1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b5a5f",
   "metadata": {},
   "source": [
    "# Models Training (Multiple Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49d8f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.48739495798319327\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.54      0.49        68\n",
      "           1       0.49      0.62      0.55        72\n",
      "           2       0.42      0.44      0.43        57\n",
      "           3       0.52      0.57      0.55        58\n",
      "           4       0.31      0.17      0.22        66\n",
      "           5       0.32      0.32      0.32        76\n",
      "           6       0.58      0.92      0.71        71\n",
      "           7       0.83      0.90      0.87        61\n",
      "           8       0.41      0.45      0.43        53\n",
      "           9       0.29      0.10      0.15        61\n",
      "          10       0.59      0.71      0.65        63\n",
      "          11       0.44      0.45      0.45        53\n",
      "          12       0.31      0.16      0.21        68\n",
      "          13       0.38      0.49      0.43        55\n",
      "          14       0.61      0.93      0.74        57\n",
      "          15       0.37      0.24      0.29        63\n",
      "          16       0.55      0.32      0.40        69\n",
      "\n",
      "    accuracy                           0.49      1071\n",
      "   macro avg       0.46      0.49      0.46      1071\n",
      "weighted avg       0.46      0.49      0.46      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[37  4  0  0  0  7  0  0  4  1 10  3  0  2  0  0  0]\n",
      " [ 2 45  0  0  0  7  0  0 13  0  0  0  0  5  0  0  0]\n",
      " [ 0  0 25  5  1  1  9  1  0  0  2  0  4  1  2  2  4]\n",
      " [ 0  0  2 33  0  0  2  1  0  0  0  0  0  0 11  0  9]\n",
      " [ 6  5  7  3 11  9  7  1  2  3  0  3  3  2  1  2  1]\n",
      " [ 8  9  0  0  1 24  1  0  1  7  1  5  3 12  0  4  0]\n",
      " [ 0  0  0  0  1  2 65  0  0  1  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 55  0  0  0  0  0  0  3  0  0]\n",
      " [ 4 18  0  0  0  1  0  0 24  0  6  0  0  0  0  0  0]\n",
      " [10  1  0  0  3  8  8  0  1  6  2  8  6  6  0  2  0]\n",
      " [ 8  2  0  0  1  0  4  0  2  1 45  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  4  6  3  0  4  1  0 24  1  3  0  6  0]\n",
      " [ 2  2  8  3  5  2  7  0  3  0  4  0 11  6  8  5  2]\n",
      " [ 1  2  2  0  3  0  0  0  5  1  1  4  4 27  0  5  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0  0  0 53  0  1]\n",
      " [ 4  3  3  0  5  8  1  2  0  0  2  7  4  7  1 15  1]\n",
      " [ 0  0 13 13  0  1  5  6  0  0  1  0  0  0  8  0 22]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6470588235294118\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        68\n",
      "           1       0.60      0.83      0.70        72\n",
      "           2       0.60      0.74      0.66        57\n",
      "           3       0.69      0.86      0.77        58\n",
      "           4       0.55      0.18      0.27        66\n",
      "           5       0.41      0.32      0.36        76\n",
      "           6       0.70      0.93      0.80        71\n",
      "           7       0.86      0.93      0.90        61\n",
      "           8       0.65      0.81      0.72        53\n",
      "           9       0.38      0.33      0.35        61\n",
      "          10       0.84      0.86      0.85        63\n",
      "          11       0.82      0.51      0.63        53\n",
      "          12       0.65      0.51      0.57        68\n",
      "          13       0.53      0.85      0.65        55\n",
      "          14       0.77      0.93      0.84        57\n",
      "          15       0.67      0.44      0.53        63\n",
      "          16       0.77      0.48      0.59        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.66      0.63      1071\n",
      "weighted avg       0.65      0.65      0.63      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  6  0  0  0  4  0  0  2  4  6  0  0  3  0  1  0]\n",
      " [ 1 60  0  0  0  1  0  0  5  0  0  0  1  3  0  1  0]\n",
      " [ 0  0 42  2  2  1  4  0  0  0  0  0  2  0  0  3  1]\n",
      " [ 0  0  2 50  0  0  0  1  0  0  0  0  0  0  3  0  2]\n",
      " [ 5  8  7  1 12  7  5  2  1  7  0  2  4  3  1  1  0]\n",
      " [10  7  1  0  1 24  1  1  5 12  0  1  1 11  0  1  0]\n",
      " [ 0  0  0  0  0  1 66  0  0  2  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  1 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 1  8  0  0  0  1  0  0 43  0  0  0  0  0  0  0  0]\n",
      " [ 8  1  1  0  0  7  6  1  3 20  1  0  4  5  0  4  0]\n",
      " [ 2  1  4  0  0  0  0  0  0  1 54  0  0  1  0  0  0]\n",
      " [ 0  3  1  0  3  5  0  1  3  2  1 27  1  3  0  3  0]\n",
      " [ 2  1  0  3  2  1  8  0  2  0  1  1 35  4  4  0  4]\n",
      " [ 0  3  0  0  0  1  0  0  2  1  0  1  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0  0  0  1  0 53  0  0]\n",
      " [ 5  2  3  0  2  4  0  0  0  3  0  1  4  9  1 28  1]\n",
      " [ 0  0  9 15  0  2  2  1  0  0  0  0  1  0  6  0 33]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.6470588235294118\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        68\n",
      "           1       0.60      0.83      0.70        72\n",
      "           2       0.60      0.74      0.66        57\n",
      "           3       0.69      0.86      0.77        58\n",
      "           4       0.55      0.18      0.27        66\n",
      "           5       0.41      0.32      0.36        76\n",
      "           6       0.70      0.93      0.80        71\n",
      "           7       0.86      0.93      0.90        61\n",
      "           8       0.65      0.81      0.72        53\n",
      "           9       0.38      0.33      0.35        61\n",
      "          10       0.84      0.86      0.85        63\n",
      "          11       0.82      0.51      0.63        53\n",
      "          12       0.65      0.51      0.57        68\n",
      "          13       0.53      0.85      0.65        55\n",
      "          14       0.77      0.93      0.84        57\n",
      "          15       0.67      0.44      0.53        63\n",
      "          16       0.77      0.48      0.59        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.66      0.63      1071\n",
      "weighted avg       0.65      0.65      0.63      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  6  0  0  0  4  0  0  2  4  6  0  0  3  0  1  0]\n",
      " [ 1 60  0  0  0  1  0  0  5  0  0  0  1  3  0  1  0]\n",
      " [ 0  0 42  2  2  1  4  0  0  0  0  0  2  0  0  3  1]\n",
      " [ 0  0  2 50  0  0  0  1  0  0  0  0  0  0  3  0  2]\n",
      " [ 5  8  7  1 12  7  5  2  1  7  0  2  4  3  1  1  0]\n",
      " [10  7  1  0  1 24  1  1  5 12  0  1  1 11  0  1  0]\n",
      " [ 0  0  0  0  0  1 66  0  0  2  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  1 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 1  8  0  0  0  1  0  0 43  0  0  0  0  0  0  0  0]\n",
      " [ 8  1  1  0  0  7  6  1  3 20  1  0  4  5  0  4  0]\n",
      " [ 2  1  4  0  0  0  0  0  0  1 54  0  0  1  0  0  0]\n",
      " [ 0  3  1  0  3  5  0  1  3  2  1 27  1  3  0  3  0]\n",
      " [ 2  1  0  3  2  1  8  0  2  0  1  1 35  4  4  0  4]\n",
      " [ 0  3  0  0  0  1  0  0  2  1  0  1  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0  0  0  1  0 53  0  0]\n",
      " [ 5  2  3  0  2  4  0  0  0  3  0  1  4  9  1 28  1]\n",
      " [ 0  0  9 15  0  2  2  1  0  0  0  0  1  0  6  0 33]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.8375350140056023\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        68\n",
      "           1       0.82      0.97      0.89        72\n",
      "           2       0.74      0.96      0.84        57\n",
      "           3       0.92      0.95      0.93        58\n",
      "           4       0.81      0.45      0.58        66\n",
      "           5       0.58      0.42      0.49        76\n",
      "           6       0.92      1.00      0.96        71\n",
      "           7       0.97      0.93      0.95        61\n",
      "           8       0.73      0.98      0.84        53\n",
      "           9       0.75      0.64      0.69        61\n",
      "          10       0.91      1.00      0.95        63\n",
      "          11       0.91      0.77      0.84        53\n",
      "          12       0.92      0.88      0.90        68\n",
      "          13       0.75      0.95      0.84        55\n",
      "          14       0.88      1.00      0.93        57\n",
      "          15       0.91      0.78      0.84        63\n",
      "          16       0.95      0.80      0.87        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.84      0.84      0.83      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[59  4  0  0  1  3  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 70  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 55  0  0  0  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 2  2  8  0 30  6  1  0  4  2  2  2  3  0  1  2  1]\n",
      " [ 9  4  0  0  2 32  1  0  5  8  0  1  0 11  0  3  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 57  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  1  0  0  8  1  0  3 39  3  1  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  2  4  0  0  2  1  0 41  0  1  0  0  0]\n",
      " [ 0  0  2  0  1  0  1  0  0  0  1  0 60  1  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 4  1  2  0  1  1  0  0  0  1  0  0  0  4  0 49  0]\n",
      " [ 0  0  6  4  0  0  1  1  1  0  0  0  0  0  1  0 55]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.6778711484593838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63        68\n",
      "           1       0.73      0.78      0.75        72\n",
      "           2       0.63      0.86      0.73        57\n",
      "           3       0.60      0.81      0.69        58\n",
      "           4       0.35      0.17      0.23        66\n",
      "           5       0.35      0.14      0.21        76\n",
      "           6       0.83      0.92      0.87        71\n",
      "           7       0.90      0.72      0.80        61\n",
      "           8       0.67      0.91      0.77        53\n",
      "           9       0.44      0.48      0.46        61\n",
      "          10       0.81      0.92      0.86        63\n",
      "          11       0.71      0.64      0.67        53\n",
      "          12       0.71      0.79      0.75        68\n",
      "          13       0.69      0.80      0.74        55\n",
      "          14       0.82      0.89      0.86        57\n",
      "          15       0.65      0.62      0.63        63\n",
      "          16       0.78      0.58      0.67        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.66      0.69      0.67      1071\n",
      "weighted avg       0.66      0.68      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[46  2  0  0  0  3  0  0  1  8  6  0  0  0  0  2  0]\n",
      " [ 4 56  0  0  1  0  0  0  4  1  1  0  1  1  0  3  0]\n",
      " [ 0  0 49  1  0  0  0  0  0  0  2  0  0  0  1  1  3]\n",
      " [ 0  0  4 47  0  0  0  1  0  1  0  0  0  0  3  0  2]\n",
      " [ 4  5  5  5 11  6  6  1  2  7  1  1  6  1  1  1  3]\n",
      " [10  6  2  0  7 11  1  1  6  9  0  3  6 10  0  4  0]\n",
      " [ 0  0  1  2  0  0 65  0  0  2  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  3  2  0  1 44  0  2  0  1  2  1  1  1  2]\n",
      " [ 1  4  0  0  0  0  0  0 48  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  2  1  3  3  1  1  2 29  1  4  4  0  0  3  1]\n",
      " [ 2  0  2  0  0  0  0  0  0  1 58  0  0  0  0  0  0]\n",
      " [ 0  2  2  0  0  5  0  0  3  2  1 34  1  2  1  0  0]\n",
      " [ 1  1  2  2  0  0  1  0  0  2  1  1 54  0  0  3  0]\n",
      " [ 2  0  0  0  4  0  0  0  3  0  0  0  0 44  1  1  0]\n",
      " [ 0  0  1  1  0  1  0  0  0  0  0  0  1  1 51  1  0]\n",
      " [ 2  1  1  4  2  1  1  0  3  2  0  4  0  3  0 39  0]\n",
      " [ 0  0  6 12  1  1  2  1  0  0  1  0  1  1  2  1 40]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.6937441643323996\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68        68\n",
      "           1       0.76      0.88      0.81        72\n",
      "           2       0.74      0.74      0.74        57\n",
      "           3       0.83      0.76      0.79        58\n",
      "           4       0.40      0.39      0.40        66\n",
      "           5       0.40      0.25      0.31        76\n",
      "           6       0.90      0.85      0.87        71\n",
      "           7       0.94      0.77      0.85        61\n",
      "           8       0.81      0.89      0.85        53\n",
      "           9       0.52      0.57      0.55        61\n",
      "          10       0.78      0.86      0.82        63\n",
      "          11       0.59      0.68      0.63        53\n",
      "          12       0.64      0.71      0.67        68\n",
      "          13       0.65      0.76      0.70        55\n",
      "          14       0.84      0.91      0.87        57\n",
      "          15       0.69      0.49      0.57        63\n",
      "          16       0.68      0.71      0.70        69\n",
      "\n",
      "    accuracy                           0.69      1071\n",
      "   macro avg       0.69      0.70      0.69      1071\n",
      "weighted avg       0.69      0.69      0.69      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48  4  0  0  1  8  0  0  0  1  4  0  1  1  0  0  0]\n",
      " [ 2 63  0  0  0  1  0  0  2  2  0  1  1  0  0  0  0]\n",
      " [ 0  0 42  1  1  1  0  0  0  2  0  0  3  1  0  1  5]\n",
      " [ 0  0  0 44  2  0  0  2  0  0  0  0  1  0  4  0  5]\n",
      " [ 3  3  5  0 26  4  2  0  2  5  2  3  2  0  1  3  5]\n",
      " [ 7  5  0  0 10 19  1  0  2  7  1  8  4  9  0  3  0]\n",
      " [ 0  0  0  0  3  2 60  0  0  3  1  0  2  0  0  0  0]\n",
      " [ 0  0  1  0  5  0  0 47  0  0  0  0  2  0  3  0  3]\n",
      " [ 2  2  0  0  0  0  0  0 47  0  1  1  0  0  0  0  0]\n",
      " [ 7  0  0  0  3  3  1  0  2 35  3  3  3  0  0  0  1]\n",
      " [ 0  1  0  0  0  2  0  0  1  4 54  0  1  0  0  0  0]\n",
      " [ 0  3  0  0  2  1  2  0  2  2  0 36  4  0  0  1  0]\n",
      " [ 1  0  1  1  4  1  1  0  0  2  0  0 48  3  1  2  3]\n",
      " [ 1  1  1  0  1  0  0  0  0  3  1  3  1 42  0  1  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  0  2  0 52  0  1]\n",
      " [ 3  1  2  0  3  6  0  0  0  0  2  6  0  9  0 31  0]\n",
      " [ 0  0  4  6  4  0  0  1  0  1  0  0  0  0  1  3 49]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.3099906629318394\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.22      0.32        68\n",
      "           1       0.64      0.53      0.58        72\n",
      "           2       0.18      0.05      0.08        57\n",
      "           3       0.30      0.05      0.09        58\n",
      "           4       0.50      0.06      0.11        66\n",
      "           5       0.45      0.18      0.26        76\n",
      "           6       0.31      1.00      0.47        71\n",
      "           7       0.95      0.85      0.90        61\n",
      "           8       0.64      0.17      0.27        53\n",
      "           9       0.20      0.03      0.06        61\n",
      "          10       0.69      0.35      0.46        63\n",
      "          11       0.60      0.23      0.33        53\n",
      "          12       0.50      0.13      0.21        68\n",
      "          13       0.11      0.96      0.20        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.50      0.06      0.11        63\n",
      "          16       0.47      0.30      0.37        69\n",
      "\n",
      "    accuracy                           0.31      1071\n",
      "   macro avg       0.45      0.31      0.28      1071\n",
      "weighted avg       0.45      0.31      0.29      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  0  0  0  0  3  4  0  1  0  4  2  0 39  0  0  0]\n",
      " [ 0 38  0  0  0  2  3  0  3  0  0  0  2 24  0  0  0]\n",
      " [ 0  0  3  0  1  1 16  0  0  0  0  0  0 31  0  2  3]\n",
      " [ 0  0  0  3  0  0 15  1  0  0  0  0  0 23  3  0 13]\n",
      " [ 3  3  0  3  4  3 13  0  0  2  0  3  3 26  0  0  3]\n",
      " [ 4  6  0  0  1 14 12  0  0  2  0  1  1 34  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  3 52  0  0  0  0  0  3  0  0  2]\n",
      " [ 0  3  0  0  0  0  0  0  9  1  1  0  0 39  0  0  0]\n",
      " [ 2  1  1  0  1  2 16  0  0  2  4  1  1 30  0  0  0]\n",
      " [ 3  6  0  0  0  0  9  0  0  1 22  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  1 13  0  0  0  0 12  1 25  0  1  0]\n",
      " [ 0  1  7  0  0  0 21  0  1  0  1  0  9 27  0  0  1]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0 11  1  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  1  0  1  2  6  0  0  1  0  1  1 44  0  4  2]\n",
      " [ 0  0  5  3  0  2 16  1  0  1  0  0  0 20  0  0 21]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.8375350140056023\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        68\n",
      "           1       0.82      0.97      0.89        72\n",
      "           2       0.74      0.96      0.84        57\n",
      "           3       0.92      0.95      0.93        58\n",
      "           4       0.81      0.45      0.58        66\n",
      "           5       0.58      0.42      0.49        76\n",
      "           6       0.92      1.00      0.96        71\n",
      "           7       0.97      0.93      0.95        61\n",
      "           8       0.73      0.98      0.84        53\n",
      "           9       0.75      0.64      0.69        61\n",
      "          10       0.91      1.00      0.95        63\n",
      "          11       0.91      0.77      0.84        53\n",
      "          12       0.92      0.88      0.90        68\n",
      "          13       0.75      0.95      0.84        55\n",
      "          14       0.88      1.00      0.93        57\n",
      "          15       0.91      0.78      0.84        63\n",
      "          16       0.95      0.80      0.87        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.84      0.84      0.83      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[59  4  0  0  1  3  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 70  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 55  0  0  0  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 2  2  8  0 30  6  1  0  4  2  2  2  3  0  1  2  1]\n",
      " [ 9  4  0  0  2 32  1  0  5  8  0  1  0 11  0  3  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 57  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  1  0  0  8  1  0  3 39  3  1  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  2  4  0  0  2  1  0 41  0  1  0  0  0]\n",
      " [ 0  0  2  0  1  0  1  0  0  0  1  0 60  1  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 4  1  2  0  1  1  0  0  0  1  0  0  0  4  0 49  0]\n",
      " [ 0  0  6  4  0  0  1  1  1  0  0  0  0  0  1  0 55]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.6778711484593838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63        68\n",
      "           1       0.73      0.78      0.75        72\n",
      "           2       0.63      0.86      0.73        57\n",
      "           3       0.60      0.81      0.69        58\n",
      "           4       0.35      0.17      0.23        66\n",
      "           5       0.35      0.14      0.21        76\n",
      "           6       0.83      0.92      0.87        71\n",
      "           7       0.90      0.72      0.80        61\n",
      "           8       0.67      0.91      0.77        53\n",
      "           9       0.44      0.48      0.46        61\n",
      "          10       0.81      0.92      0.86        63\n",
      "          11       0.71      0.64      0.67        53\n",
      "          12       0.71      0.79      0.75        68\n",
      "          13       0.69      0.80      0.74        55\n",
      "          14       0.82      0.89      0.86        57\n",
      "          15       0.65      0.62      0.63        63\n",
      "          16       0.78      0.58      0.67        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.66      0.69      0.67      1071\n",
      "weighted avg       0.66      0.68      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[46  2  0  0  0  3  0  0  1  8  6  0  0  0  0  2  0]\n",
      " [ 4 56  0  0  1  0  0  0  4  1  1  0  1  1  0  3  0]\n",
      " [ 0  0 49  1  0  0  0  0  0  0  2  0  0  0  1  1  3]\n",
      " [ 0  0  4 47  0  0  0  1  0  1  0  0  0  0  3  0  2]\n",
      " [ 4  5  5  5 11  6  6  1  2  7  1  1  6  1  1  1  3]\n",
      " [10  6  2  0  7 11  1  1  6  9  0  3  6 10  0  4  0]\n",
      " [ 0  0  1  2  0  0 65  0  0  2  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  3  2  0  1 44  0  2  0  1  2  1  1  1  2]\n",
      " [ 1  4  0  0  0  0  0  0 48  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  2  1  3  3  1  1  2 29  1  4  4  0  0  3  1]\n",
      " [ 2  0  2  0  0  0  0  0  0  1 58  0  0  0  0  0  0]\n",
      " [ 0  2  2  0  0  5  0  0  3  2  1 34  1  2  1  0  0]\n",
      " [ 1  1  2  2  0  0  1  0  0  2  1  1 54  0  0  3  0]\n",
      " [ 2  0  0  0  4  0  0  0  3  0  0  0  0 44  1  1  0]\n",
      " [ 0  0  1  1  0  1  0  0  0  0  0  0  1  1 51  1  0]\n",
      " [ 2  1  1  4  2  1  1  0  3  2  0  4  0  3  0 39  0]\n",
      " [ 0  0  6 12  1  1  2  1  0  0  1  0  1  1  2  1 40]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.6937441643323996\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68        68\n",
      "           1       0.76      0.88      0.81        72\n",
      "           2       0.74      0.74      0.74        57\n",
      "           3       0.83      0.76      0.79        58\n",
      "           4       0.40      0.39      0.40        66\n",
      "           5       0.40      0.25      0.31        76\n",
      "           6       0.90      0.85      0.87        71\n",
      "           7       0.94      0.77      0.85        61\n",
      "           8       0.81      0.89      0.85        53\n",
      "           9       0.52      0.57      0.55        61\n",
      "          10       0.78      0.86      0.82        63\n",
      "          11       0.59      0.68      0.63        53\n",
      "          12       0.64      0.71      0.67        68\n",
      "          13       0.65      0.76      0.70        55\n",
      "          14       0.84      0.91      0.87        57\n",
      "          15       0.69      0.49      0.57        63\n",
      "          16       0.68      0.71      0.70        69\n",
      "\n",
      "    accuracy                           0.69      1071\n",
      "   macro avg       0.69      0.70      0.69      1071\n",
      "weighted avg       0.69      0.69      0.69      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48  4  0  0  1  8  0  0  0  1  4  0  1  1  0  0  0]\n",
      " [ 2 63  0  0  0  1  0  0  2  2  0  1  1  0  0  0  0]\n",
      " [ 0  0 42  1  1  1  0  0  0  2  0  0  3  1  0  1  5]\n",
      " [ 0  0  0 44  2  0  0  2  0  0  0  0  1  0  4  0  5]\n",
      " [ 3  3  5  0 26  4  2  0  2  5  2  3  2  0  1  3  5]\n",
      " [ 7  5  0  0 10 19  1  0  2  7  1  8  4  9  0  3  0]\n",
      " [ 0  0  0  0  3  2 60  0  0  3  1  0  2  0  0  0  0]\n",
      " [ 0  0  1  0  5  0  0 47  0  0  0  0  2  0  3  0  3]\n",
      " [ 2  2  0  0  0  0  0  0 47  0  1  1  0  0  0  0  0]\n",
      " [ 7  0  0  0  3  3  1  0  2 35  3  3  3  0  0  0  1]\n",
      " [ 0  1  0  0  0  2  0  0  1  4 54  0  1  0  0  0  0]\n",
      " [ 0  3  0  0  2  1  2  0  2  2  0 36  4  0  0  1  0]\n",
      " [ 1  0  1  1  4  1  1  0  0  2  0  0 48  3  1  2  3]\n",
      " [ 1  1  1  0  1  0  0  0  0  3  1  3  1 42  0  1  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  0  2  0 52  0  1]\n",
      " [ 3  1  2  0  3  6  0  0  0  0  2  6  0  9  0 31  0]\n",
      " [ 0  0  4  6  4  0  0  1  0  1  0  0  0  0  1  3 49]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.3099906629318394\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.22      0.32        68\n",
      "           1       0.64      0.53      0.58        72\n",
      "           2       0.18      0.05      0.08        57\n",
      "           3       0.30      0.05      0.09        58\n",
      "           4       0.50      0.06      0.11        66\n",
      "           5       0.45      0.18      0.26        76\n",
      "           6       0.31      1.00      0.47        71\n",
      "           7       0.95      0.85      0.90        61\n",
      "           8       0.64      0.17      0.27        53\n",
      "           9       0.20      0.03      0.06        61\n",
      "          10       0.69      0.35      0.46        63\n",
      "          11       0.60      0.23      0.33        53\n",
      "          12       0.50      0.13      0.21        68\n",
      "          13       0.11      0.96      0.20        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.50      0.06      0.11        63\n",
      "          16       0.47      0.30      0.37        69\n",
      "\n",
      "    accuracy                           0.31      1071\n",
      "   macro avg       0.45      0.31      0.28      1071\n",
      "weighted avg       0.45      0.31      0.29      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  0  0  0  0  3  4  0  1  0  4  2  0 39  0  0  0]\n",
      " [ 0 38  0  0  0  2  3  0  3  0  0  0  2 24  0  0  0]\n",
      " [ 0  0  3  0  1  1 16  0  0  0  0  0  0 31  0  2  3]\n",
      " [ 0  0  0  3  0  0 15  1  0  0  0  0  0 23  3  0 13]\n",
      " [ 3  3  0  3  4  3 13  0  0  2  0  3  3 26  0  0  3]\n",
      " [ 4  6  0  0  1 14 12  0  0  2  0  1  1 34  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  3 52  0  0  0  0  0  3  0  0  2]\n",
      " [ 0  3  0  0  0  0  0  0  9  1  1  0  0 39  0  0  0]\n",
      " [ 2  1  1  0  1  2 16  0  0  2  4  1  1 30  0  0  0]\n",
      " [ 3  6  0  0  0  0  9  0  0  1 22  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  1 13  0  0  0  0 12  1 25  0  1  0]\n",
      " [ 0  1  7  0  0  0 21  0  1  0  1  0  9 27  0  0  1]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0 11  1  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  1  0  1  2  6  0  0  1  0  1  1 44  0  4  2]\n",
      " [ 0  0  5  3  0  2 16  1  0  1  0  0  0 20  0  0 21]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.21942110177404295\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      1.00      0.27        68\n",
      "           1       1.00      0.61      0.76        72\n",
      "           2       0.00      0.00      0.00        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.24      0.37      0.29        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.00      0.00      0.00        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.17      0.06      0.09        63\n",
      "          11       1.00      0.36      0.53        53\n",
      "          12       0.13      0.28      0.18        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.19      0.80      0.30        69\n",
      "\n",
      "    accuracy                           0.22      1071\n",
      "   macro avg       0.17      0.20      0.14      1071\n",
      "weighted avg       0.17      0.22      0.15      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [28 44  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  6  0  0  0  0  0 27  0  0  0 24]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [36  0  0  0  0  0  2  0  0  0  2  0 15  0  0  0 11]\n",
      " [62  0  0  0  0  0 10  0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 26  0  0  0  1  0 38  0  0  0  6]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [53  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [37  0  0  0  0  0 10  0  0  0  3  0 11  0  0  0  0]\n",
      " [51  0  0  0  0  0  6  0  0  0  4  0  2  0  0  0  0]\n",
      " [23  0  0  0  0  0  8  0  0  0  1 19  2  0  0  0  0]\n",
      " [19  0  0  0  0  0 13  0  0  0  1  0 19  0  0  0 16]\n",
      " [25  0  0  0  0  0 16  0  0  0  4  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [36  0  0  0  0  0 12  0  0  0  4  0  7  0  0  0  4]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0 55]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.21942110177404295\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      1.00      0.27        68\n",
      "           1       1.00      0.61      0.76        72\n",
      "           2       0.00      0.00      0.00        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.24      0.37      0.29        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.00      0.00      0.00        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.17      0.06      0.09        63\n",
      "          11       1.00      0.36      0.53        53\n",
      "          12       0.13      0.28      0.18        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.19      0.80      0.30        69\n",
      "\n",
      "    accuracy                           0.22      1071\n",
      "   macro avg       0.17      0.20      0.14      1071\n",
      "weighted avg       0.17      0.22      0.15      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [28 44  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  6  0  0  0  0  0 27  0  0  0 24]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [36  0  0  0  0  0  2  0  0  0  2  0 15  0  0  0 11]\n",
      " [62  0  0  0  0  0 10  0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 26  0  0  0  1  0 38  0  0  0  6]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [53  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [37  0  0  0  0  0 10  0  0  0  3  0 11  0  0  0  0]\n",
      " [51  0  0  0  0  0  6  0  0  0  4  0  2  0  0  0  0]\n",
      " [23  0  0  0  0  0  8  0  0  0  1 19  2  0  0  0  0]\n",
      " [19  0  0  0  0  0 13  0  0  0  1  0 19  0  0  0 16]\n",
      " [25  0  0  0  0  0 16  0  0  0  4  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [36  0  0  0  0  0 12  0  0  0  4  0  7  0  0  0  4]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0 55]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.7394957983193278\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74        68\n",
      "           1       0.81      0.96      0.88        72\n",
      "           2       0.60      0.86      0.71        57\n",
      "           3       0.78      0.91      0.84        58\n",
      "           4       0.50      0.17      0.25        66\n",
      "           5       0.46      0.42      0.44        76\n",
      "           6       0.82      0.99      0.90        71\n",
      "           7       0.97      0.95      0.96        61\n",
      "           8       0.76      0.98      0.86        53\n",
      "           9       0.54      0.43      0.48        61\n",
      "          10       0.88      0.95      0.92        63\n",
      "          11       0.73      0.60      0.66        53\n",
      "          12       0.75      0.60      0.67        68\n",
      "          13       0.64      0.85      0.73        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.74      0.56      0.64        63\n",
      "          16       0.85      0.67      0.75        69\n",
      "\n",
      "    accuracy                           0.74      1071\n",
      "   macro avg       0.73      0.75      0.73      1071\n",
      "weighted avg       0.73      0.74      0.72      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[55  3  0  0  1  5  0  0  0  1  0  1  1  1  0  0  0]\n",
      " [ 1 69  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 49  1  0  1  3  0  0  0  0  0  0  0  0  0  3]\n",
      " [ 0  0  0 53  0  0  0  1  0  0  0  0  1  0  2  0  1]\n",
      " [ 4  4 12  2 11 10  1  0  2  5  2  2  4  3  1  2  1]\n",
      " [10  2  0  0  2 32  1  0  3  9  1  2  0 12  0  2  0]\n",
      " [ 0  0  1  0  0  0 70  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 58  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  3  0  1  4  4  0  4 26  4  3  2  3  0  4  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  2  1  0  1  4  3  0  3  4  0 32  0  2  0  0  0]\n",
      " [ 1  0  6  2  1  3  1  0  1  1  1  1 41  3  2  2  2]\n",
      " [ 1  1  2  0  0  1  0  0  1  0  0  0  0 47  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0]\n",
      " [ 2  2  2  0  3  8  0  0  1  2  0  3  1  3  0 35  1]\n",
      " [ 0  0  5  8  2  0  2  1  0  0  0  0  4  0  1  0 46]]\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.7394957983193278\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74        68\n",
      "           1       0.81      0.96      0.88        72\n",
      "           2       0.60      0.86      0.71        57\n",
      "           3       0.78      0.91      0.84        58\n",
      "           4       0.50      0.17      0.25        66\n",
      "           5       0.46      0.42      0.44        76\n",
      "           6       0.82      0.99      0.90        71\n",
      "           7       0.97      0.95      0.96        61\n",
      "           8       0.76      0.98      0.86        53\n",
      "           9       0.54      0.43      0.48        61\n",
      "          10       0.88      0.95      0.92        63\n",
      "          11       0.73      0.60      0.66        53\n",
      "          12       0.75      0.60      0.67        68\n",
      "          13       0.64      0.85      0.73        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.74      0.56      0.64        63\n",
      "          16       0.85      0.67      0.75        69\n",
      "\n",
      "    accuracy                           0.74      1071\n",
      "   macro avg       0.73      0.75      0.73      1071\n",
      "weighted avg       0.73      0.74      0.72      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[55  3  0  0  1  5  0  0  0  1  0  1  1  1  0  0  0]\n",
      " [ 1 69  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 49  1  0  1  3  0  0  0  0  0  0  0  0  0  3]\n",
      " [ 0  0  0 53  0  0  0  1  0  0  0  0  1  0  2  0  1]\n",
      " [ 4  4 12  2 11 10  1  0  2  5  2  2  4  3  1  2  1]\n",
      " [10  2  0  0  2 32  1  0  3  9  1  2  0 12  0  2  0]\n",
      " [ 0  0  1  0  0  0 70  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 58  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  3  0  1  4  4  0  4 26  4  3  2  3  0  4  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  2  1  0  1  4  3  0  3  4  0 32  0  2  0  0  0]\n",
      " [ 1  0  6  2  1  3  1  0  1  1  1  1 41  3  2  2  2]\n",
      " [ 1  1  2  0  0  1  0  0  1  0  0  0  0 47  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0]\n",
      " [ 2  2  2  0  3  8  0  0  1  2  0  3  1  3  0 35  1]\n",
      " [ 0  0  5  8  2  0  2  1  0  0  0  0  4  0  1  0 46]]\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.8272642390289449\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.81      0.91      0.86        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.42      0.57        66\n",
      "           5       0.55      0.42      0.48        76\n",
      "           6       0.92      0.97      0.95        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.84      1.00      0.91        53\n",
      "           9       0.61      0.70      0.66        61\n",
      "          10       0.98      0.97      0.98        63\n",
      "          11       0.75      0.72      0.73        53\n",
      "          12       0.91      0.93      0.92        68\n",
      "          13       0.75      0.91      0.82        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.78      0.71      0.74        63\n",
      "          16       0.94      0.87      0.90        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.83      0.82      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  3  0  0  2  1  0  0  0  1  0  1  0  1  0  1  0]\n",
      " [ 1 68  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0]\n",
      " [ 0  0 52  0  0  1  1  0  0  1  0  0  1  0  0  0  1]\n",
      " [ 0  0  0 53  0  0  0  1  0  0  0  0  0  0  2  0  2]\n",
      " [ 4  3  6  0 28  9  2  0  2  6  1  0  2  0  1  2  0]\n",
      " [ 8  4  0  0  0 32  0  0  2 10  0  4  0 11  0  5  0]\n",
      " [ 0  0  0  0  0  0 69  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 57  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  2  0  0  4  1  0  2 43  0  3  2  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 61  0  0  1  0  0  0]\n",
      " [ 1  2  0  0  0  4  2  0  2  3  0 38  0  1  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  0  0  0  1 63  0  2  0  0]\n",
      " [ 0  0  1  0  0  2  0  0  0  0  0  0  0 50  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 1  1  0  0  1  5  0  0  0  3  0  4  0  3  0 45  0]\n",
      " [ 0  0  2  5  1  0  0  1  0  0  0  0  0  0  0  0 60]]\n",
      "==================================================\n",
      "Model: CatBoost Classifier\n",
      "Accuracy: 0.8272642390289449\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.81      0.91      0.86        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.42      0.57        66\n",
      "           5       0.55      0.42      0.48        76\n",
      "           6       0.92      0.97      0.95        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.84      1.00      0.91        53\n",
      "           9       0.61      0.70      0.66        61\n",
      "          10       0.98      0.97      0.98        63\n",
      "          11       0.75      0.72      0.73        53\n",
      "          12       0.91      0.93      0.92        68\n",
      "          13       0.75      0.91      0.82        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.78      0.71      0.74        63\n",
      "          16       0.94      0.87      0.90        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.83      0.82      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  3  0  0  2  1  0  0  0  1  0  1  0  1  0  1  0]\n",
      " [ 1 68  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0]\n",
      " [ 0  0 52  0  0  1  1  0  0  1  0  0  1  0  0  0  1]\n",
      " [ 0  0  0 53  0  0  0  1  0  0  0  0  0  0  2  0  2]\n",
      " [ 4  3  6  0 28  9  2  0  2  6  1  0  2  0  1  2  0]\n",
      " [ 8  4  0  0  0 32  0  0  2 10  0  4  0 11  0  5  0]\n",
      " [ 0  0  0  0  0  0 69  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 57  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  2  0  0  4  1  0  2 43  0  3  2  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 61  0  0  1  0  0  0]\n",
      " [ 1  2  0  0  0  4  2  0  2  3  0 38  0  1  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  0  0  0  1 63  0  2  0  0]\n",
      " [ 0  0  1  0  0  2  0  0  0  0  0  0  0 50  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 1  1  0  0  1  5  0  0  0  3  0  4  0  3  0 45  0]\n",
      " [ 0  0  2  5  1  0  0  1  0  0  0  0  0  0  0  0 60]]\n",
      "==================================================\n",
      "Model: CatBoost Classifier\n",
      "Accuracy: 0.8328664799253035\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.81        68\n",
      "           1       0.81      0.99      0.89        72\n",
      "           2       0.75      0.95      0.84        57\n",
      "           3       0.92      0.93      0.92        58\n",
      "           4       0.73      0.41      0.52        66\n",
      "           5       0.52      0.45      0.48        76\n",
      "           6       0.99      0.97      0.98        71\n",
      "           7       0.93      0.93      0.93        61\n",
      "           8       0.82      1.00      0.90        53\n",
      "           9       0.67      0.69      0.68        61\n",
      "          10       0.95      0.97      0.96        63\n",
      "          11       0.79      0.70      0.74        53\n",
      "          12       0.97      0.91      0.94        68\n",
      "          13       0.82      0.93      0.87        55\n",
      "          14       0.93      0.98      0.96        57\n",
      "          15       0.89      0.75      0.81        63\n",
      "          16       0.91      0.86      0.88        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.84      0.83      1071\n",
      "weighted avg       0.83      0.83      0.83      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  3  0  0  0  2  0  0  0  2  0  2  0  1  0  0  0]\n",
      " [ 0 71  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 54  0  0  1  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 54  1  0  0  1  0  0  0  0  0  0  1  0  1]\n",
      " [ 4  4  9  0 27  7  0  0  2  4  2  1  1  0  1  3  1]\n",
      " [ 8  5  0  0  2 34  0  0  4  9  0  5  0  7  0  2  0]\n",
      " [ 0  0  0  0  0  1 69  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  2  0  1  7  0  0  2 42  1  0  0  1  0  1  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0 61  0  0  0  0  0  0]\n",
      " [ 0  4  0  0  3  6  0  0  1  1  0 37  0  1  0  0  0]\n",
      " [ 0  0  1  0  1  2  0  0  1  0  0  0 62  0  0  0  1]\n",
      " [ 0  0  2  0  0  0  0  0  2  0  0  0  0 51  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 56  0  1]\n",
      " [ 2  1  0  0  1  4  0  0  0  4  0  2  1  1  0 47  0]\n",
      " [ 0  0  2  3  1  0  0  3  0  0  0  0  0  0  1  0 59]]\n",
      "Accuracy: 0.8328664799253035\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.81        68\n",
      "           1       0.81      0.99      0.89        72\n",
      "           2       0.75      0.95      0.84        57\n",
      "           3       0.92      0.93      0.92        58\n",
      "           4       0.73      0.41      0.52        66\n",
      "           5       0.52      0.45      0.48        76\n",
      "           6       0.99      0.97      0.98        71\n",
      "           7       0.93      0.93      0.93        61\n",
      "           8       0.82      1.00      0.90        53\n",
      "           9       0.67      0.69      0.68        61\n",
      "          10       0.95      0.97      0.96        63\n",
      "          11       0.79      0.70      0.74        53\n",
      "          12       0.97      0.91      0.94        68\n",
      "          13       0.82      0.93      0.87        55\n",
      "          14       0.93      0.98      0.96        57\n",
      "          15       0.89      0.75      0.81        63\n",
      "          16       0.91      0.86      0.88        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.84      0.83      1071\n",
      "weighted avg       0.83      0.83      0.83      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  3  0  0  0  2  0  0  0  2  0  2  0  1  0  0  0]\n",
      " [ 0 71  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 54  0  0  1  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 54  1  0  0  1  0  0  0  0  0  0  1  0  1]\n",
      " [ 4  4  9  0 27  7  0  0  2  4  2  1  1  0  1  3  1]\n",
      " [ 8  5  0  0  2 34  0  0  4  9  0  5  0  7  0  2  0]\n",
      " [ 0  0  0  0  0  1 69  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  2  0  1  7  0  0  2 42  1  0  0  1  0  1  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0 61  0  0  0  0  0  0]\n",
      " [ 0  4  0  0  3  6  0  0  1  1  0 37  0  1  0  0  0]\n",
      " [ 0  0  1  0  1  2  0  0  1  0  0  0 62  0  0  0  1]\n",
      " [ 0  0  2  0  0  0  0  0  2  0  0  0  0 51  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 56  0  1]\n",
      " [ 2  1  0  0  1  4  0  0  0  4  0  2  1  1  0 47  0]\n",
      " [ 0  0  2  3  1  0  0  3  0  0  0  0  0  0  1  0 59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"CatBoost Classifier\": CatBoostClassifier(verbose=False)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf1ebd",
   "metadata": {},
   "source": [
    "# Model Selection (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1219c0",
   "metadata": {},
   "source": [
    "# Hybrid Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5163634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training individual models for hybrid ensemble:\n",
      "============================================================\n",
      "Random Forest: 0.8319\n",
      "Random Forest: 0.8319\n",
      "XGBoost: 0.8273\n",
      "XGBoost: 0.8273\n",
      "CatBoost: 0.8338\n",
      "CatBoost: 0.8338\n",
      "Gradient Boosting: 0.7386\n",
      "\n",
      "Top 2 Models:\n",
      "1. CatBoost: 0.8338\n",
      "2. Random Forest: 0.8319\n",
      "============================================================\n",
      "Gradient Boosting: 0.7386\n",
      "\n",
      "Top 2 Models:\n",
      "1. CatBoost: 0.8338\n",
      "2. Random Forest: 0.8319\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for hybrid models\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Define top performing models based on typical performance\n",
    "# You can modify these based on your actual results from the multiple model training\n",
    "top_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train individual models and store their accuracies\n",
    "model_accuracies = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(\"Training individual models for hybrid ensemble:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in top_models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_accuracies[name] = accuracy\n",
    "    \n",
    "    print(f\"{name}: {accuracy:.4f}\")\n",
    "\n",
    "# Sort models by accuracy to get top 2\n",
    "sorted_models = sorted(model_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "top_2_models = sorted_models[:2]\n",
    "\n",
    "print(f\"\\nTop 2 Models:\")\n",
    "print(f\"1. {top_2_models[0][0]}: {top_2_models[0][1]:.4f}\")\n",
    "print(f\"2. {top_2_models[1][0]}: {top_2_models[1][1]:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45a2486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Soft Voting Hybrid Model...\n",
      "Soft Voting Hybrid Accuracy: 0.8357\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.79      0.93      0.85        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.45      0.60        66\n",
      "           5       0.56      0.43      0.49        76\n",
      "           6       0.90      0.97      0.93        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.83      1.00      0.91        53\n",
      "           9       0.66      0.72      0.69        61\n",
      "          10       0.98      0.98      0.98        63\n",
      "          11       0.79      0.70      0.74        53\n",
      "          12       0.91      0.94      0.93        68\n",
      "          13       0.77      0.91      0.83        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.84      0.75      0.79        63\n",
      "          16       0.95      0.87      0.91        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.83      0.84      0.83      1071\n",
      "\n",
      "============================================================\n",
      "Soft Voting Hybrid Accuracy: 0.8357\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.79      0.93      0.85        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.45      0.60        66\n",
      "           5       0.56      0.43      0.49        76\n",
      "           6       0.90      0.97      0.93        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.83      1.00      0.91        53\n",
      "           9       0.66      0.72      0.69        61\n",
      "          10       0.98      0.98      0.98        63\n",
      "          11       0.79      0.70      0.74        53\n",
      "          12       0.91      0.94      0.93        68\n",
      "          13       0.77      0.91      0.83        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.84      0.75      0.79        63\n",
      "          16       0.95      0.87      0.91        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.83      0.84      0.83      1071\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create Voting Classifier using top 2 models\n",
    "top_model_1 = trained_models[top_2_models[0][0]]\n",
    "top_model_2 = trained_models[top_2_models[1][0]]\n",
    "\n",
    "# Method 1: Soft Voting Classifier (uses probabilities)\n",
    "voting_hybrid = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('model1', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('model2', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # Uses probabilities for better results\n",
    ")\n",
    "\n",
    "print(\"Training Soft Voting Hybrid Model...\")\n",
    "voting_hybrid.fit(X_train_scaled, y_train)\n",
    "y_pred_voting = voting_hybrid.predict(X_test_scaled)\n",
    "voting_accuracy = accuracy_score(y_test, y_pred_voting)\n",
    "\n",
    "print(f\"Soft Voting Hybrid Accuracy: {voting_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ecbc8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking Hybrid Model...\n",
      "Stacking Hybrid Accuracy: 0.8497\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83        68\n",
      "           1       0.85      0.96      0.90        72\n",
      "           2       0.82      0.96      0.89        57\n",
      "           3       0.90      0.93      0.92        58\n",
      "           4       0.74      0.48      0.59        66\n",
      "           5       0.55      0.55      0.55        76\n",
      "           6       0.97      0.97      0.97        71\n",
      "           7       0.97      0.93      0.95        61\n",
      "           8       0.90      0.98      0.94        53\n",
      "           9       0.64      0.70      0.67        61\n",
      "          10       0.97      0.97      0.97        63\n",
      "          11       0.80      0.68      0.73        53\n",
      "          12       0.91      0.94      0.93        68\n",
      "          13       0.85      0.91      0.88        55\n",
      "          14       0.95      0.98      0.97        57\n",
      "          15       0.93      0.79      0.85        63\n",
      "          16       0.91      0.90      0.91        69\n",
      "\n",
      "    accuracy                           0.85      1071\n",
      "   macro avg       0.85      0.85      0.85      1071\n",
      "weighted avg       0.85      0.85      0.85      1071\n",
      "\n",
      "============================================================\n",
      "Stacking Hybrid Accuracy: 0.8497\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83        68\n",
      "           1       0.85      0.96      0.90        72\n",
      "           2       0.82      0.96      0.89        57\n",
      "           3       0.90      0.93      0.92        58\n",
      "           4       0.74      0.48      0.59        66\n",
      "           5       0.55      0.55      0.55        76\n",
      "           6       0.97      0.97      0.97        71\n",
      "           7       0.97      0.93      0.95        61\n",
      "           8       0.90      0.98      0.94        53\n",
      "           9       0.64      0.70      0.67        61\n",
      "          10       0.97      0.97      0.97        63\n",
      "          11       0.80      0.68      0.73        53\n",
      "          12       0.91      0.94      0.93        68\n",
      "          13       0.85      0.91      0.88        55\n",
      "          14       0.95      0.98      0.97        57\n",
      "          15       0.93      0.79      0.85        63\n",
      "          16       0.91      0.90      0.91        69\n",
      "\n",
      "    accuracy                           0.85      1071\n",
      "   macro avg       0.85      0.85      0.85      1071\n",
      "weighted avg       0.85      0.85      0.85      1071\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Stacking Classifier (more advanced ensemble)\n",
    "stacking_hybrid = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
    "        ('catboost', CatBoostClassifier(verbose=False, random_state=42))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5  # 5-fold cross-validation\n",
    ")\n",
    "\n",
    "print(\"Training Stacking Hybrid Model...\")\n",
    "stacking_hybrid.fit(X_train_scaled, y_train)\n",
    "y_pred_stacking = stacking_hybrid.predict(X_test_scaled)\n",
    "stacking_accuracy = accuracy_score(y_test, y_pred_stacking)\n",
    "\n",
    "print(f\"Stacking Hybrid Accuracy: {stacking_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_stacking))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36d21b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Weighted Hybrid Model...\n",
      "Weighted Hybrid Accuracy: 0.8357\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.79      0.93      0.85        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.45      0.60        66\n",
      "           5       0.56      0.43      0.49        76\n",
      "           6       0.90      0.97      0.93        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.83      1.00      0.91        53\n",
      "           9       0.66      0.72      0.69        61\n",
      "          10       0.98      0.98      0.98        63\n",
      "          11       0.79      0.70      0.74        53\n",
      "          12       0.91      0.94      0.93        68\n",
      "          13       0.77      0.91      0.83        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.84      0.75      0.79        63\n",
      "          16       0.95      0.87      0.91        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.83      0.84      0.83      1071\n",
      "\n",
      "============================================================\n",
      "Weighted Hybrid Accuracy: 0.8357\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.79      0.93      0.85        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.45      0.60        66\n",
      "           5       0.56      0.43      0.49        76\n",
      "           6       0.90      0.97      0.93        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.83      1.00      0.91        53\n",
      "           9       0.66      0.72      0.69        61\n",
      "          10       0.98      0.98      0.98        63\n",
      "          11       0.79      0.70      0.74        53\n",
      "          12       0.91      0.94      0.93        68\n",
      "          13       0.77      0.91      0.83        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.84      0.75      0.79        63\n",
      "          16       0.95      0.87      0.91        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.83      0.84      0.83      1071\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Custom Weighted Ensemble\n",
    "class WeightedHybridModel:\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weights = weights if weights else [1/len(models)] * len(models)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predictions = np.array([model.predict_proba(X) for model in self.models])\n",
    "        weighted_pred = np.average(predictions, axis=0, weights=self.weights)\n",
    "        return weighted_pred\n",
    "    \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)\n",
    "\n",
    "# Create weighted ensemble with optimized weights based on individual performance\n",
    "weights = []\n",
    "total_acc = sum(model_accuracies.values())\n",
    "for name in ['Random Forest', 'XGBoost']:\n",
    "    if name in model_accuracies:\n",
    "        weights.append(model_accuracies[name] / total_acc * 2)  # Normalize weights\n",
    "\n",
    "weighted_models = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "]\n",
    "\n",
    "weighted_hybrid = WeightedHybridModel(weighted_models, weights)\n",
    "\n",
    "print(\"Training Weighted Hybrid Model...\")\n",
    "weighted_hybrid.fit(X_train_scaled, y_train)\n",
    "y_pred_weighted = weighted_hybrid.predict(X_test_scaled)\n",
    "weighted_accuracy = accuracy_score(y_test, y_pred_weighted)\n",
    "\n",
    "print(f\"Weighted Hybrid Accuracy: {weighted_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_weighted))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc427e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID MODEL COMPARISON:\n",
      "============================================================\n",
      "Soft Voting Hybrid: 0.8357\n",
      "Stacking Hybrid: 0.8497\n",
      "Weighted Hybrid: 0.8357\n",
      "\n",
      "BEST HYBRID MODEL: Stacking\n",
      "BEST HYBRID ACCURACY: 0.8497\n",
      "\n",
      "Final Hybrid Model Selected: Stacking\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare all hybrid models and select the best one\n",
    "hybrid_results = {\n",
    "    'Soft Voting': voting_accuracy,\n",
    "    'Stacking': stacking_accuracy, \n",
    "    'Weighted': weighted_accuracy\n",
    "}\n",
    "\n",
    "print(\"HYBRID MODEL COMPARISON:\")\n",
    "print(\"=\"*60)\n",
    "for name, acc in hybrid_results.items():\n",
    "    print(f\"{name} Hybrid: {acc:.4f}\")\n",
    "\n",
    "# Find the best hybrid model\n",
    "best_hybrid_name = max(hybrid_results, key=hybrid_results.get)\n",
    "best_hybrid_accuracy = hybrid_results[best_hybrid_name]\n",
    "\n",
    "print(f\"\\nBEST HYBRID MODEL: {best_hybrid_name}\")\n",
    "print(f\"BEST HYBRID ACCURACY: {best_hybrid_accuracy:.4f}\")\n",
    "\n",
    "# Select the best model for final use\n",
    "if best_hybrid_name == 'Soft Voting':\n",
    "    final_hybrid_model = voting_hybrid\n",
    "elif best_hybrid_name == 'Stacking':\n",
    "    final_hybrid_model = stacking_hybrid\n",
    "else:\n",
    "    final_hybrid_model = weighted_hybrid\n",
    "\n",
    "print(f\"\\nFinal Hybrid Model Selected: {best_hybrid_name}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19cd24ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING HYBRID MODEL:\n",
      "============================================================\n",
      "\n",
      "Test Sample 10:\n",
      "Actual Label: 12\n",
      "Hybrid Prediction: 12\n",
      "✓ Correct Prediction!\n",
      "\n",
      "Test Sample 23:\n",
      "Actual Label: 3\n",
      "Hybrid Prediction: 3\n",
      "✓ Correct Prediction!\n",
      "\n",
      "Test Sample 50:\n",
      "Actual Label: 12\n",
      "Hybrid Prediction: 12\n",
      "✓ Correct Prediction!\n",
      "\n",
      "Test Sample 75:\n",
      "Actual Label: 11\n",
      "Hybrid Prediction: 11\n",
      "✓ Correct Prediction!\n",
      "\n",
      "Test Sample 100:\n",
      "Actual Label: 12\n",
      "Hybrid Prediction: 12\n",
      "✓ Correct Prediction!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the hybrid model with sample predictions\n",
    "print(\"TESTING HYBRID MODEL:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test on multiple samples\n",
    "test_indices = [10, 23, 50, 75, 100]\n",
    "\n",
    "for idx in test_indices:\n",
    "    print(f\"\\nTest Sample {idx}:\")\n",
    "    print(f\"Actual Label: {y_test.iloc[idx]}\")\n",
    "    \n",
    "    # Get prediction from hybrid model\n",
    "    if hasattr(final_hybrid_model, 'predict_proba'):\n",
    "        hybrid_pred = final_hybrid_model.predict(X_test_scaled[idx].reshape(1, -1))[0]\n",
    "    else:\n",
    "        hybrid_pred = final_hybrid_model.predict(X_test_scaled[idx].reshape(1, -1))[0]\n",
    "    \n",
    "    print(f\"Hybrid Prediction: {hybrid_pred}\")\n",
    "    \n",
    "    if y_test.iloc[idx] == hybrid_pred:\n",
    "        print(\"✓ Correct Prediction!\")\n",
    "    else:\n",
    "        print(\"✗ Incorrect Prediction\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3124b92",
   "metadata": {},
   "source": [
    "# Save Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79aae4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model saved successfully!\n",
      "Model Type: Stacking Hybrid\n",
      "Accuracy: 0.8497\n",
      "Files saved:\n",
      "- Models/scaler.pkl\n",
      "- Models/hybrid_model.pkl\n",
      "- Models/model_info.pkl\n",
      "\n",
      "Model Type: Stacking Hybrid\n",
      "Accuracy: 0.8497\n",
      "Files saved:\n",
      "- Models/scaler.pkl\n",
      "- Models/hybrid_model.pkl\n",
      "- Models/model_info.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the best hybrid model\n",
    "import pickle\n",
    "\n",
    "# Save the hybrid model (overwrites the previous single model)\n",
    "pickle.dump(scaler, open(\"Models/scaler.pkl\", 'wb'))\n",
    "pickle.dump(final_hybrid_model, open(\"Models/hybrid_model.pkl\", 'wb'))\n",
    "\n",
    "# Also save model metadata\n",
    "model_info = {\n",
    "    'model_type': 'hybrid',\n",
    "    'hybrid_method': best_hybrid_name,\n",
    "    'accuracy': best_hybrid_accuracy,\n",
    "    'components': ['Random Forest', 'XGBoost'] if best_hybrid_name != 'Stacking' else ['Random Forest', 'XGBoost', 'CatBoost']\n",
    "}\n",
    "\n",
    "pickle.dump(model_info, open(\"Models/model_info.pkl\", 'wb'))\n",
    "\n",
    "print(\"Hybrid model saved successfully!\")\n",
    "print(f\"Model Type: {best_hybrid_name} Hybrid\")\n",
    "print(f\"Accuracy: {best_hybrid_accuracy:.4f}\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- Models/scaler.pkl\")\n",
    "print(\"- Models/hybrid_model.pkl\") \n",
    "print(\"- Models/model_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7bc95",
   "metadata": {},
   "source": [
    "# Hybrid Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c54c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Recommendation System Loaded!\n",
      "Model Type: Hybrid - Stacking\n",
      "Model Accuracy: 0.8497\n",
      "Components: Random Forest, XGBoost, CatBoost\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Recommendation System using Hybrid Model\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the hybrid model and scaler\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "hybrid_model = pickle.load(open(\"Models/hybrid_model.pkl\", 'rb'))\n",
    "model_info = pickle.load(open(\"Models/model_info.pkl\", 'rb'))\n",
    "\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n",
    "               'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "               'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "               'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "               'Real Estate Developer']\n",
    "\n",
    "def HybridRecommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                         weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                         chemistry_score, biology_score, english_score, geography_score,\n",
    "                         total_score, average_score):\n",
    "    \"\"\"\n",
    "    Enhanced career recommendation system using hybrid model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "    \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score, total_score, average_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    \n",
    "    # Predict using the hybrid model\n",
    "    if hasattr(hybrid_model, 'predict_proba'):\n",
    "        probabilities = hybrid_model.predict_proba(scaled_features)\n",
    "    else:\n",
    "        # For custom weighted model\n",
    "        probabilities = hybrid_model.predict_proba(scaled_features)\n",
    "    \n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs, model_info\n",
    "\n",
    "print(\"Hybrid Recommendation System Loaded!\")\n",
    "print(f\"Model Type: {model_info['model_type'].title()} - {model_info['hybrid_method']}\")\n",
    "print(f\"Model Accuracy: {model_info['accuracy']:.4f}\")\n",
    "print(f\"Components: {', '.join(model_info['components'])}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8da43b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID RECOMMENDATION SYSTEM - TEST 1\n",
      "============================================================\n",
      "Student Profile: Strong in Physics & Chemistry, Good overall performance\n",
      "Top 5 Career Recommendations:\n",
      "----------------------------------------\n",
      "1. Teacher: 0.9719 (97.2%)\n",
      "2. Unknown: 0.0070 (0.7%)\n",
      "3. Government Officer: 0.0054 (0.5%)\n",
      "4. Banker: 0.0043 (0.4%)\n",
      "5. Real Estate Developer: 0.0040 (0.4%)\n",
      "\n",
      "Using Stacking Hybrid Model (Accuracy: 0.8497)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Hybrid Recommendation System - Example 1\n",
    "print(\"HYBRID RECOMMENDATION SYSTEM - TEST 1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_recommendations, model_info = HybridRecommendations(\n",
    "    gender='female',\n",
    "    part_time_job=False,\n",
    "    absence_days=2,\n",
    "    extracurricular_activities=False,\n",
    "    weekly_self_study_hours=7,\n",
    "    math_score=65,\n",
    "    history_score=60,\n",
    "    physics_score=97,\n",
    "    chemistry_score=94,\n",
    "    biology_score=71,\n",
    "    english_score=81,\n",
    "    geography_score=66,\n",
    "    total_score=534,\n",
    "    average_score=76.285714\n",
    ")\n",
    "\n",
    "print(\"Student Profile: Strong in Physics & Chemistry, Good overall performance\")\n",
    "print(\"Top 5 Career Recommendations:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (class_name, probability) in enumerate(final_recommendations, 1):\n",
    "    print(f\"{i}. {class_name}: {probability:.4f} ({probability*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nUsing {model_info['hybrid_method']} Hybrid Model (Accuracy: {model_info['accuracy']:.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "145b52d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID RECOMMENDATION SYSTEM - TEST 2\n",
      "============================================================\n",
      "Student Profile: Strong in Math & Physics, Active in extracurriculars\n",
      "Top 5 Career Recommendations:\n",
      "----------------------------------------\n",
      "1. Accountant: 0.5708 (57.1%)\n",
      "2. Unknown: 0.1015 (10.2%)\n",
      "3. Software Engineer: 0.0823 (8.2%)\n",
      "4. Business Owner: 0.0777 (7.8%)\n",
      "5. Stock Investor: 0.0453 (4.5%)\n",
      "\n",
      "Using Stacking Hybrid Model (Accuracy: 0.8497)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Hybrid Recommendation System - Example 2\n",
    "print(\"HYBRID RECOMMENDATION SYSTEM - TEST 2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_recommendations_2, _ = HybridRecommendations(\n",
    "    gender='male',\n",
    "    part_time_job=True,\n",
    "    absence_days=5,\n",
    "    extracurricular_activities=True,\n",
    "    weekly_self_study_hours=10,\n",
    "    math_score=95,\n",
    "    history_score=45,\n",
    "    physics_score=88,\n",
    "    chemistry_score=90,\n",
    "    biology_score=55,\n",
    "    english_score=70,\n",
    "    geography_score=62,\n",
    "    total_score=505,\n",
    "    average_score=72.14\n",
    ")\n",
    "\n",
    "print(\"Student Profile: Strong in Math & Physics, Active in extracurriculars\")\n",
    "print(\"Top 5 Career Recommendations:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (class_name, probability) in enumerate(final_recommendations_2, 1):\n",
    "    print(f\"{i}. {class_name}: {probability:.4f} ({probability*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nUsing {model_info['hybrid_method']} Hybrid Model (Accuracy: {model_info['accuracy']:.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "406327da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8300653594771242\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.81        68\n",
      "           1       0.83      0.97      0.90        72\n",
      "           2       0.74      0.95      0.83        57\n",
      "           3       0.89      0.95      0.92        58\n",
      "           4       0.76      0.44      0.56        66\n",
      "           5       0.54      0.34      0.42        76\n",
      "           6       0.93      1.00      0.97        71\n",
      "           7       0.95      0.92      0.93        61\n",
      "           8       0.75      0.98      0.85        53\n",
      "           9       0.74      0.74      0.74        61\n",
      "          10       0.94      0.95      0.94        63\n",
      "          11       0.81      0.74      0.77        53\n",
      "          12       0.91      0.87      0.89        68\n",
      "          13       0.77      0.93      0.84        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.91      0.81      0.86        63\n",
      "          16       0.90      0.81      0.85        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.84      0.82      1071\n",
      "weighted avg       0.82      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:  [[59  3  0  0  1  1  0  0  0  0  0  3  0  0  0  1  0]\n",
      " [ 0 70  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 54  0  0  0  1  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 5  2  8  0 29  8  0  0  2  3  1  3  2  0  1  0  2]\n",
      " [ 8  4  0  0  4 26  2  0  6  9  0  2  1 11  0  3  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 56  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  4  1  0  2 45  2  1  2  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  1  0 60  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  2  5  0  0  2  2  0 39  0  1  0  0  0]\n",
      " [ 0  0  1  0  1  1  1  0  0  1  1  0 59  1  1  0  1]\n",
      " [ 0  0  2  0  0  0  0  0  1  0  0  0  0 51  0  1  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0 56  0  0]\n",
      " [ 2  1  2  0  0  3  0  0  1  1  0  0  0  2  0 51  0]\n",
      " [ 0  0  4  5  0  0  0  2  1  0  0  0  0  0  1  0 56]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"Report: \",classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297114b",
   "metadata": {},
   "source": [
    "# Single Input Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6ff0f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 12\n",
      "Model Prediction : 12\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "print(\"Actual Label :\", y_test.iloc[10])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28bdd4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 3\n",
      "Model Prediction : 3\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "print(\"Actual Label :\", y_test.iloc[23])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[23].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d133441-293d-41bc-8dd0-e99a975925e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 12\n",
      "Model Prediction: 12\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# Test sample 3\n",
    "print(\"Actual Label:\", y_test.iloc[50])\n",
    "print(\"Model Prediction:\", model.predict(X_test_scaled[50].reshape(1, -1))[0])\n",
    "if y_test.iloc[50] == model.predict(X_test_scaled[50].reshape(1, -1))[0]:\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"Not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "900b1bb6-1803-4f7f-be17-7f68f5a199ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 11\n",
      "Model Prediction: 11\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# Test sample 4\n",
    "print(\"Actual Label:\", y_test.iloc[75])\n",
    "print(\"Model Prediction:\", model.predict(X_test_scaled[75].reshape(1, -1))[0])\n",
    "if y_test.iloc[75] == model.predict(X_test_scaled[75].reshape(1, -1))[0]:\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"Not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14d88273-3fc7-4848-b452-f915860d671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 12\n",
      "Model Prediction: 12\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "#test 5\n",
    "print(\"Actual Label:\", y_test.iloc[100])\n",
    "print(\"Model Prediction:\", model.predict(X_test_scaled[100].reshape(1, -1))[0])\n",
    "if y_test.iloc[100] == model.predict(X_test_scaled[100].reshape(1, -1))[0]:\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"Not sure......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cc97f",
   "metadata": {},
   "source": [
    "# Saving & Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "549160af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SAVE FILES\n",
    "pickle.dump(scaler,open(\"Models/scaler.pkl\",'wb'))\n",
    "pickle.dump(model,open(\"Models/model.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ae2de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the scaler, label encoder, and model\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0238be1",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eff89839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n",
    "               'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "               'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "               'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "               'Real Estate Developer']\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score,average_score):\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "    \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score,total_score,average_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    \n",
    "    # Predict using the model\n",
    "    probabilities = model.predict_proba(scaled_features)\n",
    "    \n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9d10c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Teacher with probability 0.78\n",
      "Government Officer with probability 0.08\n",
      "Unknown with probability 0.08\n",
      "Real Estate Developer with probability 0.06\n",
      "Artist with probability 0.0\n",
      "\n",
      "==================================================\n",
      "Teacher with probability 0.78\n",
      "Government Officer with probability 0.08\n",
      "Unknown with probability 0.08\n",
      "Real Estate Developer with probability 0.06\n",
      "Artist with probability 0.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27160dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Artist with probability 0.66\n",
      "Game Developer with probability 0.17\n",
      "Real Estate Developer with probability 0.04\n",
      "Unknown with probability 0.03\n",
      "Business Owner with probability 0.02\n"
     ]
    }
   ],
   "source": [
    "# Example usage 2\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=4,\n",
    "                                        math_score=87,\n",
    "                                        history_score=73,\n",
    "                                        physics_score=98,\n",
    "                                        chemistry_score=91,\n",
    "                                        biology_score=79,\n",
    "                                        english_score=60,\n",
    "                                        geography_score=77,\n",
    "                                        total_score=583,\n",
    "                                        average_score=83.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c9aca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "# sklear version in pychar production \n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "# in pycharm env install\n",
    "# pip install scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b058bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
